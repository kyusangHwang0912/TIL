{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5장-1절. Bagging(Bootstrap aggregating)\n",
    "- Bootstraping(부트스트래핑) : 예측값과 실제값의 차이 중복을 허용한 리샘플링(복원추출)\n",
    "- 정의\n",
    "    - Boostrapping을 통해 여러 학습 데이터를 만들고, 이들을 averaging prediction을 통해 합친다!\n",
    "    \n",
    "    \n",
    "- 프로세스 예시\n",
    "    1. 1~12까지 12개의 데이터가 있다면 복원추출로 12개를 뽑는다.(안뽑히는 숫자가 존재할 수 있다.)(이때 전체데이터의 약 63%가 추출된다.)\n",
    "    2. 1번을 k번 반복해서 k개의 tree를 만든다.\n",
    "    3. k개의 tree로 각각 예측을 한다.\n",
    "    4. 그 예측값의 평균을 계산\n",
    "    5. 이 때 k개의 tree를 뽑을 때 학습데이터에서 추출되지 않는 데이터들을 활용하기위해 각각의 tree가 미추출된 데이터들을 예측하고, 이에대한 에러율을 구한다. 그 에러율의 평균은 Out-Of-Bag error(OOB error)라고 한다.\n",
    "        - 즉, 이 학습데이터 내에서도 검증데이터에 대한 성능지표를 계산할 수 있게된다. (랜덤포레스트에서도 이 OOB error 사용)    \n",
    "        \n",
    "        \n",
    "- 장점 : Tree들의 편향 유지, 분산 감소, 학습데이터의 noise에 강건해진다.\n",
    "- 단점 : 모형해석이 어렵다.(Tree는 직관적이기 때문에 해석이 쉽지만, bagging은 어려워 진다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\rbtkd\\\\ADP_codingbook\\\\앙상블'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의미없다고 판단되는 변수 제거\n",
    "data = data.drop(['id','date','zipcode','lat','long'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15129, 8), (6484, 8), (15129,), (6484,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feature_columns = list(data.columns.difference(['price']))\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = ss_scaler.fit_transform(X_train)\n",
    "X_test_scaled = ss_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 로지스틱회귀분석 - 베이스모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_X_train = sm.add_constant(X_train_scaled, has_constant='add')\n",
    "sm_model = sm.OLS(y_train, sm_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.590</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.590</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2724.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 10 Sep 2021</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:07:55</td>     <th>  Log-Likelihood:    </th> <td>-2.0875e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15129</td>      <th>  AIC:               </th>  <td>4.175e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15120</td>      <th>  BIC:               </th>  <td>4.176e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.392e+05</td> <td> 1934.240</td> <td>  278.786</td> <td> 0.000</td> <td> 5.35e+05</td> <td> 5.43e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 1.068e+05</td> <td> 3129.532</td> <td>   34.140</td> <td> 0.000</td> <td> 1.01e+05</td> <td> 1.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-4188.3511</td> <td> 2289.717</td> <td>   -1.829</td> <td> 0.067</td> <td>-8676.473</td> <td>  299.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td> 1.285e+04</td> <td> 2130.565</td> <td>    6.032</td> <td> 0.000</td> <td> 8674.840</td> <td>  1.7e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -139.0375</td> <td> 2408.550</td> <td>   -0.058</td> <td> 0.954</td> <td>-4860.087</td> <td> 4582.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> 2.294e+05</td> <td> 2663.317</td> <td>   86.120</td> <td> 0.000</td> <td> 2.24e+05</td> <td> 2.35e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> 7.127e+04</td> <td> 1954.443</td> <td>   36.464</td> <td> 0.000</td> <td> 6.74e+04</td> <td> 7.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>-1.279e+05</td> <td> 2656.843</td> <td>  -48.122</td> <td> 0.000</td> <td>-1.33e+05</td> <td>-1.23e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td> 4808.4637</td> <td> 2063.579</td> <td>    2.330</td> <td> 0.020</td> <td>  763.600</td> <td> 8853.328</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13677.883</td> <th>  Durbin-Watson:     </th>  <td>   1.961</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1681500.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.883</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>54.060</td>   <th>  Cond. No.          </th>  <td>    3.26</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.590\n",
       "Model:                            OLS   Adj. R-squared:                  0.590\n",
       "Method:                 Least Squares   F-statistic:                     2724.\n",
       "Date:                Fri, 10 Sep 2021   Prob (F-statistic):               0.00\n",
       "Time:                        16:07:55   Log-Likelihood:            -2.0875e+05\n",
       "No. Observations:               15129   AIC:                         4.175e+05\n",
       "Df Residuals:                   15120   BIC:                         4.176e+05\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.392e+05   1934.240    278.786      0.000    5.35e+05    5.43e+05\n",
       "x1          1.068e+05   3129.532     34.140      0.000    1.01e+05    1.13e+05\n",
       "x2         -4188.3511   2289.717     -1.829      0.067   -8676.473     299.770\n",
       "x3          1.285e+04   2130.565      6.032      0.000    8674.840     1.7e+04\n",
       "x4          -139.0375   2408.550     -0.058      0.954   -4860.087    4582.012\n",
       "x5          2.294e+05   2663.317     86.120      0.000    2.24e+05    2.35e+05\n",
       "x6          7.127e+04   1954.443     36.464      0.000    6.74e+04    7.51e+04\n",
       "x7         -1.279e+05   2656.843    -48.122      0.000   -1.33e+05   -1.23e+05\n",
       "x8          4808.4637   2063.579      2.330      0.020     763.600    8853.328\n",
       "==============================================================================\n",
       "Omnibus:                    13677.883   Durbin-Watson:                   1.961\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1681500.452\n",
       "Skew:                           3.883   Prob(JB):                         0.00\n",
       "Kurtosis:                      54.060   Cond. No.                         3.26\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_sm_model = sm_model.fit()\n",
    "fitted_sm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_X_test = sm.add_constant(X_test_scaled, has_constant='add')\n",
    "sm_model_predict = fitted_sm_model.predict(sm_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221736.04649882956"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "np.sqrt(mean_squared_error(y_test,sm_model_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 로지스틱회귀모델을 배깅에 이용 - for문이용 => 나중 앙상블의 앙상블에 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20992</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504246</td>\n",
       "      <td>-0.400536</td>\n",
       "      <td>-0.628343</td>\n",
       "      <td>1.874620</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>1.397736</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.154496</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.908883</td>\n",
       "      <td>-0.916463</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>0.102820</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7863</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504246</td>\n",
       "      <td>-0.400536</td>\n",
       "      <td>0.908883</td>\n",
       "      <td>-0.916463</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>0.307281</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.804746</td>\n",
       "      <td>-0.400536</td>\n",
       "      <td>-0.628343</td>\n",
       "      <td>0.944259</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>0.886585</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20369</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.804746</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>-0.628343</td>\n",
       "      <td>0.944259</td>\n",
       "      <td>1.151149</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>1.499966</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6  \\\n",
       "20992  1.0  0.504246 -0.400536 -0.628343  1.874620  0.294623 -0.089416   \n",
       "2378   1.0  1.154496  0.673118  0.908883 -0.916463  0.294623 -0.089416   \n",
       "7863   1.0  0.504246 -0.400536  0.908883 -0.916463  0.294623 -0.089416   \n",
       "6887   1.0  1.804746 -0.400536 -0.628343  0.944259  0.294623 -0.089416   \n",
       "20369  1.0  1.804746  0.673118 -0.628343  0.944259  1.151149 -0.089416   \n",
       "\n",
       "              7         8  \n",
       "20992  1.397736 -0.209477  \n",
       "2378   0.102820 -0.209477  \n",
       "7863   0.307281 -0.209477  \n",
       "6887   0.886585 -0.209477  \n",
       "20369  1.499966 -0.209477  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 밑에서 코드를 짜서 직접 돌리기 위해서는 이 과정이 이루어 져야 함 1\n",
    "sm_X_train = pd.DataFrame(sm_X_train,index=y_train.index)\n",
    "sm_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504246</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>-0.628343</td>\n",
       "      <td>0.944259</td>\n",
       "      <td>2.007674</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>0.545818</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.504246</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.908883</td>\n",
       "      <td>-0.916463</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.169793</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13505</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.146004</td>\n",
       "      <td>-1.474190</td>\n",
       "      <td>-0.628343</td>\n",
       "      <td>-0.916463</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.749098</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.179121</td>\n",
       "      <td>-0.400536</td>\n",
       "      <td>0.908883</td>\n",
       "      <td>0.944259</td>\n",
       "      <td>0.294623</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>0.409511</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.446504</td>\n",
       "      <td>-1.474190</td>\n",
       "      <td>-0.628343</td>\n",
       "      <td>-0.916463</td>\n",
       "      <td>-1.418427</td>\n",
       "      <td>-0.089416</td>\n",
       "      <td>-0.612791</td>\n",
       "      <td>-0.209477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6  \\\n",
       "11531  1.0  0.504246  0.673118 -0.628343  0.944259  2.007674 -0.089416   \n",
       "6531   1.0  0.504246  0.673118  0.908883 -0.916463  0.294623 -0.089416   \n",
       "13505  1.0 -0.146004 -1.474190 -0.628343 -0.916463  0.294623 -0.089416   \n",
       "10858  1.0  0.179121 -0.400536  0.908883  0.944259  0.294623 -0.089416   \n",
       "5687   1.0 -1.446504 -1.474190 -0.628343 -0.916463 -1.418427 -0.089416   \n",
       "\n",
       "              7         8  \n",
       "11531  0.545818 -0.209477  \n",
       "6531  -0.169793 -0.209477  \n",
       "13505 -0.749098 -0.209477  \n",
       "10858  0.409511 -0.209477  \n",
       "5687  -0.612791 -0.209477  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 밑에서 코드를 짜서 직접 돌리기 위해서는 이 과정이 이루어 져야 함 2\n",
    "sm_X_test = pd.DataFrame(sm_X_test, index=y_test.index)\n",
    "sm_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9513\n",
      "221561.73914839167\n",
      "9589\n",
      "221785.73708073085\n",
      "9548\n",
      "221678.84691074723\n",
      "9609\n",
      "222729.88932666025\n",
      "9564\n",
      "221461.80270488796\n",
      "9585\n",
      "221735.68255435672\n",
      "9585\n",
      "222001.3461592786\n",
      "9550\n",
      "222077.7291782319\n",
      "9533\n",
      "221881.1537224147\n",
      "9558\n",
      "221970.60672460884\n"
     ]
    }
   ],
   "source": [
    "# bagging을 for문으로 만들어보기\n",
    "\n",
    "bagging_predict_result = []\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(X_train.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, X_train.shape[0])\n",
    "    print(len(set(random_data_index)))\n",
    "    bg_X_train = sm_X_train.iloc[random_data_index,]\n",
    "    bg_y_train = y_train.iloc[random_data_index,]\n",
    "    sm_model = sm.OLS(bg_y_train,bg_X_train)\n",
    "    fitted_sm_model = sm_model.fit()\n",
    "    pred = fitted_sm_model.predict(sm_X_test)\n",
    "    bagging_predict_result.append(pred)\n",
    "    print(np.sqrt(mean_squared_error(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging 결과의 평균 구하기 - 결과가 리스트로 생성되기 떄문에 아래에서 [lst_index].values로 값을 지정해 주어야 됨\n",
    "bagging_predict = [] # 빈 리스트 생성\n",
    "for lst2_index in range(X_test.shape[0]): # 테스트 데이터 개수만큼의 반복\n",
    "    temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장)\n",
    "    for lst_index in range(len(bagging_predict_result)): # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(bagging_predict_result[lst_index].values[lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221692.8115700165"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "np.sqrt(mean_squared_error(bagging_predict,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 로지스틱회귀모델을 배깅에 이용 - 패키지이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221736.04649882956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "fitted_linear_model = regression_model.fit(X_train_scaled, y_train)\n",
    "pred_test_linear = fitted_linear_model.predict(X_test_scaled)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_linear)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221787.6776777772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "bagging_model = BaggingRegressor(base_estimator=regression_model, n_estimators=10)\n",
    "fitted_bagging_model = bagging_model.fit(X_train_scaled, y_train)\n",
    "pred_test_bg = fitted_bagging_model.predict(X_test_scaled)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_bg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 검증 정확도: 233584.29527415632\n"
     ]
    }
   ],
   "source": [
    "# train_test_split을 사용하지 않았을때는 교차검증을 이렇게 하는 것\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "\n",
    "regression_model = LinearRegression()\n",
    "bagging_model = BaggingRegressor(base_estimator=regression_model, n_estimators=10)\n",
    "scores = cross_val_score(bagging_model,X,y,scoring='neg_mean_squared_error',cv=5)\n",
    "print('평균 검증 정확도:', np.mean((np.sqrt(-1*scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 트리모델을 배깅에 이용 - for문이용\n",
    "- bagging은 트리모델 기반임으로 트리모델을 배깅에 이용하는게 더 성능이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267441.81575594534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr_model1 = dtr.fit(X_train_scaled, y_train)\n",
    "pred_test_dtr = dtr.predict(X_test_scaled)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_dtr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1.479993</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>-0.633445</td>\n",
       "      <td>0.933554</td>\n",
       "      <td>2.851289</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>0.645544</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17068</th>\n",
       "      <td>-0.147743</td>\n",
       "      <td>1.787389</td>\n",
       "      <td>2.438648</td>\n",
       "      <td>-0.915466</td>\n",
       "      <td>-0.555598</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>-0.877653</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21524</th>\n",
       "      <td>0.503351</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>-0.633445</td>\n",
       "      <td>0.933554</td>\n",
       "      <td>1.999567</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>1.254823</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>-0.473290</td>\n",
       "      <td>-0.407352</td>\n",
       "      <td>0.902601</td>\n",
       "      <td>-0.915466</td>\n",
       "      <td>-0.555598</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>0.239358</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>-1.449932</td>\n",
       "      <td>-0.407352</td>\n",
       "      <td>-0.633445</td>\n",
       "      <td>-0.915466</td>\n",
       "      <td>-0.555598</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>-1.080746</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "1586   1.479993  0.690018 -0.633445  0.933554  2.851289 -0.092008  0.645544   \n",
       "17068 -0.147743  1.787389  2.438648 -0.915466 -0.555598 -0.092008 -0.877653   \n",
       "21524  0.503351  0.690018 -0.633445  0.933554  1.999567 -0.092008  1.254823   \n",
       "4989  -0.473290 -0.407352  0.902601 -0.915466 -0.555598 -0.092008  0.239358   \n",
       "4188  -1.449932 -0.407352 -0.633445 -0.915466 -0.555598 -0.092008 -1.080746   \n",
       "\n",
       "              7  \n",
       "1586  -0.208961  \n",
       "17068 -0.208961  \n",
       "21524 -0.208961  \n",
       "4989  -0.208961  \n",
       "4188  -0.208961  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, index=y_train.index)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>-0.473290</td>\n",
       "      <td>-0.407352</td>\n",
       "      <td>0.902601</td>\n",
       "      <td>-0.915466</td>\n",
       "      <td>0.296124</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>-0.945351</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12273</th>\n",
       "      <td>0.828898</td>\n",
       "      <td>1.787389</td>\n",
       "      <td>2.438648</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>-0.555598</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>0.611695</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12742</th>\n",
       "      <td>-1.449932</td>\n",
       "      <td>-0.407352</td>\n",
       "      <td>-2.169492</td>\n",
       "      <td>-0.915466</td>\n",
       "      <td>-1.407320</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>-0.336072</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>0.503351</td>\n",
       "      <td>-0.407352</td>\n",
       "      <td>-0.633445</td>\n",
       "      <td>0.933554</td>\n",
       "      <td>-0.555598</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>1.153277</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>0.503351</td>\n",
       "      <td>0.690018</td>\n",
       "      <td>-0.633445</td>\n",
       "      <td>0.933554</td>\n",
       "      <td>-0.555598</td>\n",
       "      <td>-0.092008</td>\n",
       "      <td>0.747091</td>\n",
       "      <td>-0.208961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "17527 -0.473290 -0.407352  0.902601 -0.915466  0.296124 -0.092008 -0.945351   \n",
       "12273  0.828898  1.787389  2.438648  0.009044 -0.555598 -0.092008  0.611695   \n",
       "12742 -1.449932 -0.407352 -2.169492 -0.915466 -1.407320 -0.092008 -0.336072   \n",
       "6343   0.503351 -0.407352 -0.633445  0.933554 -0.555598 -0.092008  1.153277   \n",
       "5894   0.503351  0.690018 -0.633445  0.933554 -0.555598 -0.092008  0.747091   \n",
       "\n",
       "              7  \n",
       "17527 -0.208961  \n",
       "12273 -0.208961  \n",
       "12742 -0.208961  \n",
       "6343  -0.208961  \n",
       "5894  -0.208961  "
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled = pd.DataFrame(X_test_scaled, index=y_test.index)\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9538\n",
      "265025.67182190384\n",
      "9476\n",
      "289055.7504580901\n",
      "9612\n",
      "280866.52658801945\n",
      "9502\n",
      "269646.7801176419\n",
      "9542\n",
      "278810.7718611196\n",
      "9555\n",
      "282686.30726748984\n",
      "9504\n",
      "287126.8055049103\n",
      "9517\n",
      "283674.04448530613\n",
      "9596\n",
      "284506.5975839485\n",
      "9623\n",
      "278492.96912895364\n"
     ]
    }
   ],
   "source": [
    "bagging_predict_result = []\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(X_train.shape[0])]\n",
    "    random_data_index = np.random.choice(data_index, X_train.shape[0])\n",
    "    print(len(set(random_data_index)))\n",
    "    bg_X_train = X_train_scaled.iloc[random_data_index,]\n",
    "    bg_y_train = y_train.iloc[random_data_index,]\n",
    "    dtr = DecisionTreeRegressor()\n",
    "    dtr.fit(bg_X_train,bg_y_train)\n",
    "    pred_tree = dtr.predict(X_test_scaled)\n",
    "    bagging_predict_result.append(pred_tree)\n",
    "    print(np.sqrt(mean_squared_error(y_test,pred_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 주의 values는 빠져야 한다!!!\n",
    "# Bagging을 바탕으로 예측한 결과값에 대한 평균을 계산\n",
    "bagging_predict = [] # 빈 리스트 생성\n",
    "for lst2_index in range(X_test.shape[0]): # 테스트 데이터 개수만큼의 반복\n",
    "    temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장)\n",
    "    for lst_index in range(len(bagging_predict_result)): # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(bagging_predict_result[lst_index][lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228917.3976470912"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,bagging_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 트리모델을 배깅에 이용 - 패키지이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236682.62166123808"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "bagging_decision_tree_model = BaggingRegressor(base_estimator=dtr,\n",
    "                                              n_estimators=10,\n",
    "                                              verbose=1)#학습 과정 표시\n",
    "bagging_decision_tree_model.fit(X_train_scaled,y_train)\n",
    "pred_test_tree_bagging = bagging_decision_tree_model.predict(X_test_scaled)\n",
    "np.sqrt(mean_squared_error(y_test,pred_test_tree_bagging))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
